<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="A New Evaluation Benchmark for Open-Vocabulary Scene Representations"/>
  <meta property="og:title" content="OpenLex3D"/>
  <meta property="og:description" content="A New Evaluation Benchmark for Open-Vocabulary Scene Representations"/>
  <meta property="og:url" content="https://openlex3d.github.io"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/hero_fig_new.svg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Scene Understanding, Computer Vision, Open-Vocabulary Evaluation, Benchmark">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>OpenLex3D</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
  <script src="https://your-plugin-url.com/beforeafter.js"></script>
  <script type="module" src="https://cdn.jsdelivr.net/npm/@google/model-viewer@latest/dist/model-viewer.js"></script>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <script nomodule src="https://unpkg.com/@google/model-viewer/dist/model-viewer-legacy.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <style>
    .center-image {
        display: block;
        margin: 0 auto;
    }


    .blend-img-item {
        background: #f5f5f5;
    }

    .item {
        margin: 10px;
    }

    .blend-img-background {
        mix-blend-mode: multiply;
    }

    #interactive {
        position: relative;
        display: inline-block;
        width: 768px;
        aspect-ratio: 16/9;
        max-width: 100%;
        border: 2px solid #fff;
        border-radius: 6px;
        overflow: hidden;
        box-shadow: 0 0 4px #000;

    }

    #interactive canvas,
    #interactive #glfailed,
    #interactive #loading {
        display: block;
        position: absolute;
        width: 100%;
        height: 100%;
        touch-action: none;
    }

    #interactive #glfailed {
        color: #f88;
        background: black;
        display: none;
    }

    #interactive #loading {
        color: #000;
        font-size: 32px;
        font-weight: bold;
        background: rgba(255, 255, 255, 0.8);
        display: none;
    }

    .iframe-container {
        width: 50%;
        max-width: 32em;
    }

    .vframe {
        border-radius: 0.5em;
        width: 100%;
        height: auto;
        aspect-ratio: 32 / 27.5;
        max-width: 32em;
        max-height: 27.5em;
        border: none;
        box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    .large-vframe {
        border-radius: 0.5em;
        width: 100%;
        height: auto;
        aspect-ratio: 32 / 18;
        max-width: 64em;
        max-height: 36em;
        border: none;
        box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    button {
        display: block;
        width: 100%;
        padding: 10px 0;
        margin-top: 10px;
        cursor: pointer;
    }

    .modelviewer-container {
        width: 50%;
        max-width: 32em;
    }

    model-viewer {
        border-radius: 0.5em;
        width: 100%;
        max-width: 32em;
        max-height: 27.5em;
        height: auto;
        aspect-ratio: 32 / 27.5;
        border: none;
        box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    .siframe-class {
        display: flex;
        flex-wrap: nowrap;
        justify-content: center;
        gap: 1vw;
        padding: 1vw;
        align-items: start;
    }

    .siframe-class .image-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        grid-template-rows: repeat(2, 1fr);
        gap: 1vw;
        flex: 1 0 40%;
        max-width: 384px;
    }

    .siframe-class .image-grid img {
        width: 100%;
        height: auto;
        object-fit: cover;
    }

    .siframe-class .iframe-container {
        flex: 1 0 60%;
        max-width: 640px;
    }

    .siframe-class iframe {
        width: 100%;
        border-radius: 0.5em;
        max-width: 640px;
        height: auto;
        aspect-ratio: 5 / 4;
        border: none;
        box-shadow: 0 0 1em 0em rgba(0, 0, 0, 0.15);
    }

    @media (max-width: 768px) {

        .large-vframe {
            width: 100%;
        }

        .iframe-container {
            width: 100%;
        }

        model-viewer {
            max-width: 100%;
            margin: 0 auto;
        }
    }

    .load img {
        width: 100px;
        height: 70px;
        object-fit: cover;
        margin: 4px;
        border: 2px solid #fff;
        box-shadow: 0 0 4px #888;
        border-radius: 6px;
        vertical-align: bottom;
    }

    .load img:active {
        box-shadow: 0 0 4px #000;
        opacity: .8;
    }

    .megabuttons {
        position: absolute;
        left: 5px;
        bottom: 5px;
        text-transform: uppercase;
        text-align: left;
    }

    nav {
        text-align: center;
    }

    nav ul {
        list-style: none;
        padding: 0;
        margin: 20px auto;
        display: flex;
        justify-content: center;
        align-items: stretch;
        width: 100%;
        gap: 10px;
    }

    nav ul li {
        flex: 1;
        display: flex;
        margin: 0;
    }

    nav ul li a {
        display: flex;
        align-items: center;
        justify-content: center;
        background-color: #f5f5f5;
        color: #363636;
        padding: 10px 20px;
        text-decoration: none;
        border: none;
        border-radius: 5px;
        font-size: 16px;
        cursor: pointer;
        transition: background-color 0.3s ease, transform 0.2s ease;
        min-height: 50px;
        flex-grow: 1;
        box-sizing: border-box;
        overflow: hidden;
    }


    nav ul li a:hover {
        background-color: #e4e4e4;
        transform: scale(1.05);
    }

    nav ul li a:active {
        background-color: #d3d3d3;
        transform: scale(0.95);
    }

    nav ul li a.active {
        background-color: #cccccc; /* Change color to indicate active tab */
        color: #000000; /* Optional: Change text color if needed */
    }


    .dynamic-section {
        display: none;
        padding: 1rem 0;
    }



    .grid-container-2x6 {
        display: grid;
        grid-template-columns: repeat(6, 1fr);
        grid-template-rows: repeat(2, auto);
        gap: 10px;
        padding: 20px;
        max-width: 80%;
        margin: auto;
    }

    .grid-container-2x6 img {
        width: 100%;
        height: auto;
    }

    .grid-container-1x6 {
        display: grid;
        grid-template-columns: repeat(6, 1fr);
        grid-template-rows: repeat(1, auto);
        gap: 10px;
        padding: 20px;
        max-width: 80%;
        margin: auto;
    }

    .grid-container-1x6 img {
        width: 100%;
        height: auto;
    }

    .panel-style {
        background-color: #fafafa;
        padding: 20px;
        margin: 20px auto;
        border: 1px solid #ccc;
        border-radius: 8px;
    }
</style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">OpenLex3D: A New Benchmark for Open-Vocabulary 3D Scene Representations</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ckassab.github.io/" target="_blank">Christina Kassab</a><sup>*,1</sup></span>
                &nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://sachamorin.github.io/" target="_blank">Sacha Morin</a><sup>*,2,4</sup></span>
                  &nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://rl.uni-freiburg.de/people/buechner" target="_blank">Martin BÃ¼chner</a><sup>*,3</sup></span>
                  &nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://mmattamala.github.io/" target="_blank">Matias Mattamala</a><sup>1</sup>
                  </span>
                  <br>
                  <span class="author-block">
                    <a href="https://www.kumaradityag.com/" target="_blank">Kumaraditya Gupta</a><sup>2,4</sup>
                  </span>
                  &nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://rl.uni-freiburg.de/people/valada" target="_blank">Abhinav Valada</a><sup>3</sup>
                  </span>
                  &nbsp;&nbsp;
                  <span class="author-block">
                    <a href="http://liampaull.ca/" target="_blank">Liam Paull</a><sup>2,4,5</sup>
                  </span>
                  &nbsp;&nbsp;
                  <span class="author-block">
                    <a href="https://ori.ox.ac.uk/people/maurice-fallon/" target="_blank">Maurice Fallon</a><sup>1</sup>
                  </span>
                  &nbsp;&nbsp;
                  </div>

                  <div class="is-size-5 publication-authors">
                    <br>
                    <sup>1</sup><span class="author-block">University of Oxford</span>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                    <sup>2</sup><span class="author-block">UniversitÃ© de MontrÃ©al</span>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                    <sup>3</sup><span class="author-block">University of Freiburg</span>
                    <br>
                    <sup>4</sup><span class="author-block">Mila - Quebec AI Institute</span>
                    &nbsp;&nbsp;&nbsp;&nbsp;
                    <sup>5</sup><span class="author-block">Canada CIFAR AI Chair</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2503.19764.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ori-drs/openlex3d" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.19764" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

               <!-- Data link -->
               <span class="link-block">
                <a href="insert_link" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-database"></i>
                </span>
                <span>Data (Coming Soon)</span>
              </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Replace the video with an image -->
      <img src="static/images/hero_fig_new.svg" alt="Banner Image" id="tree" style="width: 100%; height: auto;">
      
      <h2 class="subtitle has-text-centered">
        <strong>TL;DR</strong> Unlike closed-vocabulary evaluation, the OpenLex3D evaluation benchmark provides a manifold of label categories of varying precision which allows detailed analysis of open-vocabulary scene representation methods.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->


<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            3D scene understanding enables embodied agents to perceive and interact with their environment. Recent advances in visual-language models have introduced open-vocabulary capabilities which generalize beyond predefined label sets. However, evaluating these representations remains challenging. Most current evaluation methods rely on closed-set metrics or task-specific demonstrations. To address this, we introduce OpenLex3D, a benchmark designed to comprehensively assess open-vocabulary scene representations. OpenLex3D enhances 23 scenes from widely used indoor RGB-D datasets (Replica, ScanNet++, HM3D) with human-annotated labels that capture real-world linguistic variability and span multiple accuracy levels. The benchmark features two tasks for assessment: 3D object segmentation and object retrieval. We use OpenLex3D to evaluate both object-centric and dense open-vocabulary methods and provide deeper insights into their strengths and limitations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-left">
        <div class="has-text-centered">
          <h2 class="title is-3">Benchmark Design</h2>
            <img src="static/images/example-labels.svg" id="example-labels" style="width: 70%; height: auto;">
        </div>
        <br>
          <p>
            We create new label sets for three widely-used RGB-D datasets: ScanNet++, Replica, and HM3D. The label sets consist of different categories with varying precision: <i>synonyms</i> being the most precise; <i>depictions</i>, which include, e.g. printed images on objects; <i>visually similar</i>, which refer to objects with comparable appearance; and <i>clutter</i>, which acccounts for label pertubation due to imprecise segmentation or crop scaling.
          </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-left">
        <div class="has-text-centered">
          <h2 class="title is-3">Metrics</h2>
            <img src="static/images/metrics-web.svg" id="example-labels" style="width: 100%; height: auto;">
        </div>
          <p>
           We provide evaluation on two tasks using our label sets: semantic segmentation and object retrieval given a text query. We introduce two novel open-set metrics (above) for segmentation and an extended query set for object retrieval. 
          </p>
          <br>
          <p>
            The two semantic segmentation metrics evaluate on either the object-level or the feature level. (a) Top-N IoU measures whether any of the top-N responses contain a label from category C. (b) Set Ranking evaluates the ranking of the responses, assessing how closely the predicted rankings align with ideal rankings of categories.
           </p>
      </div>
    </div>
  </div>
</section>


<section class="section hero is-light">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
              <h2 class="title is-3">Semantic Segmentation Evaluation</h2>
              <div class="columns is-centered has-text-justified">
                <div class="column">
                    <p> We show Top-5 IoU results colored by category class. Object-centric methods that segment in 3D (OpenMask3D, Kassab2024) often miss points due to generalization or depth quality issues. Those merging 2D segments (ConceptGraphs, HOV-SG) tend to merge small segments together, leading to misclassifications. Dense representations (ConceptFusion, OpenScene) produce noisier predictions due to point-level features aggregating information from various context scales.</p>
            
                </div>
            </div>
              <p style="text-align: left;">
                For set ranking and object retrieval results tables check out the paper. We also provide evaluation visualization tools in our toolkit.
              </p>
              <br>
              <br>
              <div class="hide-on-touchscreens" style="
              display: flex;
              justify-content: center;
              gap: 1.5em;
              padding-top: 0.5em;
            ">
                      <div>
                          <i class="ti ti-view-360-arrow"></i> <strong>Left-click</strong> and
                          drag to rotate
                      </div>
                      <div>
                          <i class="ti ti-arrows-move"></i> <strong>Right-click</strong> and
                          drag or
                          <strong>WASD</strong>
                          to move
                      </div>
                      <div><i class="ti ti-zoom"></i> <strong>Scroll</strong> to zoom</div>
                  </div>
                  <br>
              <div id="wrapper" style="
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            align-items: center;
            gap: 2em;
          ">
                  <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width, fits 3 in a row -->
                    <h3><a href="https://concept-graphs.github.io/"><strong>ConceptGraphs</strong></a></h3>
                    <br>
                    <model-viewer id="model1" camera-orbit="-0.5479deg 88.7deg 14.18m"
                        camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/cg-room0.glb"
                        alt="cg" camera-controls interaction-prompt="none" exposure="0.5">
                    </model-viewer>
                  </div>
        
                  <!-- Model Viewer 2 -->
                  <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                    <h3><a href="https://hovsg.github.io/"><strong>HOV-SG</strong></a></h3>
                    <br>
                    <model-viewer id="model2" camera-orbit="-0.5479deg 88.7deg 14.18m"
                    camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/hovsg-room0.glb"
                        alt="hovsg" camera-controls interaction-prompt="none" exposure="0.5">
                    </model-viewer>
                  </div>
        
                  <!-- Model Viewer 3 -->
                  <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                    <h3><a href="https://openmask3d.github.io/"><strong>OpenMask3D</strong></a></h3>
                    <br>
                    <model-viewer id="model3" camera-orbit="-0.5479deg 88.7deg 14.18m"
                    camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/om3d-room0.glb"
                        alt="om3d" camera-controls interaction-prompt="none" exposure="0.5">
                    </model-viewer>
                  </div>

                    <!-- Model Viewer 4-->
                    <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                      <h3><strong>ConceptGraphs (GPT)</strong></h3>
                      <br>
                      <model-viewer id="model4" camera-orbit="-0.5479deg 88.7deg 14.18m"
                      camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/cg-gpt-room0.glb"
                          alt="cg-gpt" camera-controls interaction-prompt="none" exposure="0.5">
                      </model-viewer>
                    </div>

                     <!-- Model Viewer 5-->
                     <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                      <h3><a href="https://arxiv.org/abs/2412.01539"><strong>Kassab2024</strong></a></h3>
                      <br>
                      <model-viewer id="model5" camera-orbit="-0.5479deg 88.7deg 14.18m"
                      camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/kassab-room0.glb"
                          alt="kassab" camera-controls interaction-prompt="none" exposure="0.5">
                      </model-viewer>
                    </div>

                    <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                      <h3><a href="https://concept-fusion.github.io/"><strong>ConceptFusion</strong></a></h3>
                      <br>
                      <model-viewer id="model6" camera-orbit="-0.5479deg 88.7deg 14.18m"
                      camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/cf-room0.glb"
                          alt="cf" camera-controls interaction-prompt="none" exposure="0.5">
                      </model-viewer>
                    </div>

                    <div class="modelviewer-container" style="flex: 0 1 30%;"> <!-- Takes up 30% width -->
                      <h3><a href="https://pengsongyou.github.io/openscene"><strong>OpenScene</strong></a></h3>
                      <br>
                      <br>
                      <model-viewer id="model7" camera-orbit="-0.5479deg 88.7deg 14.18m"
                      camera-target="2.44m 1.04m -0.95" data-src="./static/glbs_gd/openscene-room0.glb"
                          alt="openscene" camera-controls interaction-prompt="none" exposure="0.5">
                      </model-viewer>
                    </div>
              </div>
              <br>
              <img src="static/images/legend.svg" alt="Banner Image" id="tree" style="width: 100%; height: auto;">
              <script>
                document.addEventListener('DOMContentLoaded', () => {
                    // Initialize model viewers and observers
                    const models = [];
                    const modelCount = 7; // Change this number if the number of models changes
            
                    for (let i = 1; i <= modelCount; i++) {
                        const modelViewer = document.getElementById(`model${i}`);
                        models.push(modelViewer);
            
                        const observer = new IntersectionObserver((entries) => {
                            if (entries[0].isIntersecting) {
                                const realSrc = modelViewer.dataset.src;
                                modelViewer.setAttribute('src', realSrc);
                                observer.unobserve(modelViewer);
                            }
                        });
                        observer.observe(modelViewer);
            
                        modelViewer.addEventListener('load', () => {
                            const threeCamera = modelViewer.getCameraOrbit();
                            const fov = 17.6;
                            modelViewer.camera.fieldOfView = fov;
                            modelViewer.camera.updateProjectionMatrix();
                        });
                    }
                });
            
                // Syncing logic for all models
                let syncing = false;
                let syncTimeouts = Array(7).fill(null); // Array to store timeout IDs for each model
                const SYNC_DELAY_MS = 100;
            
                // Loop to set up camera synchronization for each model
                for (let i = 1; i <= 7; i++) {
                    const model = document.getElementById(`model${i}`);
            
                    model.addEventListener('camera-change', () => {
                        if (!syncing) {
                            if (syncTimeouts[i - 1]) {
                                clearTimeout(syncTimeouts[i - 1]);
                            }
            
                            syncTimeouts[i - 1] = setTimeout(() => {
                                syncing = true;
            
                                // Synchronize cameras between all models
                                for (let j = 1; j <= 7; j++) {
                                    if (i !== j) {
                                        const sourceModel = document.getElementById(`model${i}`);
                                        const targetModel = document.getElementById(`model${j}`);
                                        copyCameraSettings(sourceModel, targetModel);
                                    }
                                }
            
                                requestAnimationFrame(() => {
                                    syncing = false;
                                });
                            }, SYNC_DELAY_MS);
                        }
                    });
                }
            
                // Function to copy camera settings from one model to another
                function copyCameraSettings(sourceModel, targetModel) {
                    const orbit = sourceModel.getCameraOrbit();
                    const fieldOfView = sourceModel.getFieldOfView();
                    const target = sourceModel.getCameraTarget();
            
                    targetModel.cameraOrbit = `${orbit.theta}rad ${orbit.phi}rad ${orbit.radius}m`;
                    targetModel.fieldOfView = `${fieldOfView}deg`;
                    targetModel.cameraTarget = `${target.x}m ${target.y}m ${target.z}m`;
            
                    console.log('Camera Orbit:', targetModel.cameraOrbit);
                    console.log('Camera FOV:', targetModel.fieldOfView);
                    console.log('Camera Target:', targetModel.cameraTarget);
                }
            </script>
             

          </div>
      </div>
  </div>
</section>

<section class="section"> 
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Acknowledgements</h2>
        <div class="content has-text-justified">
          <p>
            The authors would like to thank Ulrich-Michael, Frances, James, Maryam, and Mandolyn for their help in labeling the dataset. The work at the UniversitÃ© de MontrÃ©al was supported by the Natural Sciences and Engineering Research Council of Canada (NSERC) (Paull), an NSERC PGS D Scholarship (Morin) and an FRQNT Doctoral Scholarship (Morin).  Moreover, this research was enabled in part by compute resources provided by Mila (mila.quebec). The work at the University of Freiburg was funded by an academic grant from NVIDIA. The work at the University of Oxford was supported by a Royal Society University Research Fellowship (Fallon, Kassab), and EPSRC C2C Grant EP/Z531212/1 (Mattamala).
          </p>
        </div>
      </div>
    </div>
  </div>
</section> 

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
